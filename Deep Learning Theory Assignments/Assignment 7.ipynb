{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6bd03c",
   "metadata": {},
   "source": [
    "# Assignment 07 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a248256",
   "metadata": {},
   "source": [
    "#### 1.\tCan you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4af6b6",
   "metadata": {},
   "source": [
    "**Answer**Applications for different RNN architectures:\n",
    "\n",
    "Sequence-to-Sequence RNN: Machine Translation, Speech Recognition, Text Summarization, Language Generation, Video Captioning.\n",
    "Sequence-to-Vector RNN: Sentiment Analysis, Document Classification, Video Classification (from a sequence of frames to a single label).\n",
    "Vector-to-Sequence RNN: Image Captioning (from an image representation to a sequence of words), Music Generation (from a latent vector to a sequence of musical notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f184",
   "metadata": {},
   "source": [
    "#### 2.\tHow many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc70ad",
   "metadata": {},
   "source": [
    "**Answer**The inputs to an RNN layer must have three dimensions: (batch_size, timesteps, input_features).\n",
    "\n",
    "Batch Size: The number of samples in each batch.\n",
    "Timesteps: The number of time steps in a sequence.\n",
    "Input Features: The number of features at each time step.\n",
    "The outputs of an RNN layer also have three dimensions: (batch_size, timesteps, output_features).\n",
    "\n",
    "Batch Size: The number of samples in each batch.\n",
    "Timesteps: The number of time steps in the output sequence.\n",
    "Output Features: The number of features in the output at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7aaa4",
   "metadata": {},
   "source": [
    "#### 3.\tIf you want to build a deep sequence-to-sequence RNN, which RNN layers should have return_sequences=True? What about a sequence-to-vector RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736f403",
   "metadata": {},
   "source": [
    "**Answer**In a deep sequence-to-sequence RNN, all RNN layers except the last one should have return_sequences=True. This setting ensures that all intermediate RNN layers produce sequences that can be passed to the next RNN layer in the stack.\n",
    "\n",
    "For a sequence-to-vector RNN, all RNN layers can have return_sequences=False (which is the default). The final RNN layer will output a single vector representing the sequence's entire information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cb7cc",
   "metadata": {},
   "source": [
    "#### 4.\tSuppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aac757",
   "metadata": {},
   "source": [
    "**Answer**For forecasting the next seven days in a daily univariate time series, you can use an RNN architecture like the Sequence-to-Vector RNN. You would input a sequence of historical daily values and aim to predict a single vector containing the next seven days' forecasts. The output vector would have seven elements, each representing the forecast for one day. Optionally, you can use an encoder-decoder architecture (Sequence-to-Sequence RNN) to capture temporal dependencies and forecast multiple future time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cbd41",
   "metadata": {},
   "source": [
    "#### 5.\tWhat are the main difficulties when training RNNs? How can you handle them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c88993",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Main difficulties when training RNNs and their solutions:\n",
    "\n",
    "Vanishing Gradient Problem: RNNs can have difficulty learning long-term dependencies due to vanishing gradients. To handle this, use techniques like LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit) cells that have mechanisms to retain long-term memory.\n",
    "\n",
    "Exploding Gradient Problem: RNNs may encounter exploding gradients during training. To address this, use gradient clipping to limit the magnitude of gradients during backpropagation.\n",
    "\n",
    "Memory Constraints: RNNs require storing hidden states for each time step, leading to memory limitations. Use truncated backpropagation through time or techniques like attention mechanisms to manage memory usage.\n",
    "\n",
    "Slow Training: Training RNNs can be time-consuming due to sequential computation. Use optimized RNN libraries (e.g., CuDNN) and consider using GPUs or TPUs to speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e479268",
   "metadata": {},
   "source": [
    "#### 6.\tCan you sketch the LSTM cellâ€™s architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c4d50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71bd58a",
   "metadata": {},
   "source": [
    "#### 7.\tWhy would you want to use 1D convolutional layers in an RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098ea10",
   "metadata": {},
   "source": [
    "**Answer**1D Convolutional Layers in RNNs:\n",
    "1D convolutional layers can be used in RNNs to learn local patterns and capture short-term dependencies in sequential data. They act as feature extractors that help detect local patterns, and when combined with RNNs, they can enhance the model's ability to capture both short-term and long-term dependencies in sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16db75",
   "metadata": {},
   "source": [
    "#### 8.\tWhich neural network architecture could you use to classify videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c2162",
   "metadata": {},
   "source": [
    "**Answer**A 3D Convolutional Neural Network (3D CNN) could be used to classify videos. 3D CNNs can process spatiotemporal data and capture both spatial features within individual frames and temporal patterns across frames. They are effective for action recognition and video classification tasks, where information in both spatial and temporal dimensions is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e3af2",
   "metadata": {},
   "source": [
    "#### 9.\tTrain a classification model for the SketchRNN dataset, available in TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e393f66d",
   "metadata": {},
   "source": [
    "**Answer**Training a classification model for the SketchRNN dataset using TensorFlow Datasets requires a significant amount of code, data preprocessing, and model architecture design, which cannot be provided in a short answer. However, here is a high-level overview of the steps involved:\n",
    "\n",
    "Load the SketchRNN dataset using TensorFlow Datasets.\n",
    "Preprocess the data by converting sketches into fixed-length sequences of points or using other representations like stroke-3 format.\n",
    "Build a classification model using RNNs or other suitable architectures.\n",
    "Compile the model with an appropriate loss function and optimizer.\n",
    "Train the model on the preprocessed data using the fit() function.\n",
    "Evaluate the model on the test set to measure its performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
