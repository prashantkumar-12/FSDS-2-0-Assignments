{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6bd03c",
   "metadata": {},
   "source": [
    "# Assignment 11 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a248256",
   "metadata": {},
   "source": [
    "#### 1.\tWrite the Python code to implement a single neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b808c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "import numpy as np\n",
    "\n",
    "def single_neuron(inputs, weights, bias):\n",
    "    output = np.dot(inputs, weights) + bias\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f184",
   "metadata": {},
   "source": [
    "#### 2.\tWrite the Python code to implement ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e5112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7aaa4",
   "metadata": {},
   "source": [
    "#### 3.\tWrite the Python code for a dense layer in terms of matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886898ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dense_layer(inputs, weights, bias):\n",
    "    output = np.dot(inputs, weights) + bias\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cb7cc",
   "metadata": {},
   "source": [
    "#### 4.\tWrite the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf6693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dense_layer_plain(inputs, weights, bias):\n",
    "    output = [sum(x * w for x, w in zip(inputs, weights_row)) + bias_row for weights_row, bias_row in zip(weights, bias)]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cbd41",
   "metadata": {},
   "source": [
    "#### 5.\tWhat is the “hidden size” of a layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b15cbf",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Hidden Size of a Layer:\n",
    "The \"hidden size\" of a layer refers to the number of neurons or units in that layer. It determines the dimensionality of the layer's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e479268",
   "metadata": {},
   "source": [
    "#### 6.\tWhat does the t method do in PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a02af",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "t Method in PyTorch:\n",
    "The .t() method in PyTorch is used to transpose a tensor, swapping its dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71bd58a",
   "metadata": {},
   "source": [
    "#### 7.\tWhy is matrix multiplication written in plain Python very slow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e28e4e",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Slow Matrix Multiplication in Plain Python:\n",
    "Matrix multiplication in plain Python is slow due to the lack of optimizations that hardware-accelerated libraries like NumPy or dedicated hardware like GPUs provide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16db75",
   "metadata": {},
   "source": [
    "#### 8.\tIn matmul, why is ac==br?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2a80d",
   "metadata": {},
   "source": [
    "\n",
    "**Answer**\n",
    "Condition for Matrix Multiplication (ac==br):\n",
    "In matrix multiplication (A * B), the number of columns in matrix A must be equal to the number of rows in matrix B (ac == br) for the operation to be valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e3af2",
   "metadata": {},
   "source": [
    "#### 9.\tIn Jupyter Notebook, how do you measure the time taken for a single cell to execute?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378577a9",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Measure Execution Time in Jupyter Notebook:\n",
    "Use the %time or %timeit magic command before the code cell to measure execution time. For example: %timeit some_function()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77bd31",
   "metadata": {},
   "source": [
    "#### 10.\tWhat is elementwise arithmetic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded7b04",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Elementwise Arithmetic:\n",
    "Elementwise arithmetic involves performing operations on corresponding elements of arrays or tensors, rather than matrix operations. It is faster than matrix multiplication and can leverage hardware optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2fdc0",
   "metadata": {},
   "source": [
    "#### 11.\tWrite the PyTorch code to test whether every element of a is greater than the corresponding element of b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fbadf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([0, 2, 4])\n",
    "result = a > b\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ba3dd",
   "metadata": {},
   "source": [
    "#### 12.\tWhat is a rank-0 tensor? How do you convert it to a plain Python data type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86d41f",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Rank-0 Tensor Conversion:\n",
    "A rank-0 tensor is a scalar. To convert it to a plain Python data type, use the .item() method. For example: tensor_item = tensor_scalar.item()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e79117",
   "metadata": {},
   "source": [
    "#### 13.\tHow does elementwise arithmetic help us speed up matmul?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90790ee",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Elementwise Arithmetic and Matrix Multiplication:\n",
    "Elementwise arithmetic allows operations to be performed in parallel on individual elements, leveraging hardware optimization and improving speed. Matrix multiplication benefits from this by using optimized elementwise operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43354d",
   "metadata": {},
   "source": [
    "#### 14.\tWhat are the broadcasting rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d0f64",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Broadcasting Rules:\n",
    "Broadcasting allows operations between arrays or tensors of different shapes by automatically expanding the smaller dimension to match the larger one. Broadcasting follows specific rules to determine how dimensions can be aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5204b7",
   "metadata": {},
   "source": [
    "#### 15.\tWhat is expand_as? Show an example of how it can be used to match the results of broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c46689",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "expand_as in PyTorch:\n",
    "The expand_as method in PyTorch is used to expand the dimensions of a tensor to match the dimensions of another tensor. For example:\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[10], [20]])\n",
    "expanded_b = b.expand_as(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecbfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
