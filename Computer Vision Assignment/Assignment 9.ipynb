{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 09 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. What are the advantages of a CNN for image classification over a completely linked DNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e78d4",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Advantages of CNN over Completely Linked DNN for Image Classification:\n",
    "\n",
    "CNNs exploit local spatial correlations in images.\n",
    "CNNs use shared weights for translational invariance.\n",
    "CNNs have fewer parameters due to weight sharing.\n",
    "CNNs reduce computational complexity through pooling and convolutional operations.\n",
    "CNNs are well-suited for hierarchical feature extraction in images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two, and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does the CNN have in total? How much RAM would this network need when making a single instance prediction if we're using 32-bit floats? What if you were to practice on a batch of 50 images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10980afd",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Criteria and RAM Usage in CNN:\n",
    "\n",
    "The CNN has a total of (100 + 200 + 400) = 700 function maps.\n",
    "RAM usage for a single instance prediction: (200 x 300 x 3 x 32) bits = 18,240,000 bits = 2.28 MB.\n",
    "For a batch of 50 images: 50 x 2.28 MB = 114 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. What are five things you might do to fix the problem if your GPU runs out of memory while training a CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed2a7b",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Solutions for GPU Memory Issue:\n",
    "\n",
    "Reduce batch size.\n",
    "Use mixed-precision training (float16 instead of float32).\n",
    "Reduce model complexity (e.g., fewer layers or units).\n",
    "Utilize gradient accumulation.\n",
    "Optimize memory usage during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. Why would you use a max pooling layer instead with a convolutional layer of the same stride ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85147a48",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Max Pooling vs. Convolution with Same Stride: Max pooling reduces spatial dimensions, discarding non-maximal values, while a convolution with the same stride preserves all values but maintains spatial dimensions. Max pooling emphasizes dominant features and introduces a level of translation invariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. When would a local response normalization layer be useful ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6d2c9",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Usefulness of Local Response Normalization: Local response normalization can be useful when you want to encourage competition among adjacent neurons in a feature map, enhancing the selectivity of features and potentially increasing network robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and ResNet's core innovations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c83a1",
   "metadata": {},
   "source": [
    "**Answer**Innovations in Different Architectures:\n",
    "\n",
    "AlexNet: Introduction of ReLU activation, dropout, and data augmentation.\n",
    "GoogLeNet: Use of inception modules to capture features at multiple scales.\n",
    "ResNet: Introduction of residual blocks with skip connections to mitigate vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. On MNIST, build your own CNN and strive to achieve the best possible accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14573222",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. Using Inception v3 to classify broad images. \n",
    "1. Images of different animals can be downloaded. Load them in Python using the matplotlib.image.mpimg.imread() or scipy.misc.imread() functions, for example. Resize and/or crop them to 299 x 299 pixels, and make sure they only have three channels (RGB) and no transparency. The photos used to train the Inception model were preprocessed to have values ranging from -1.0 to 1.0, so make sure yours do as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65a965",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "Using Inception v3 for Image Classification:\n",
    "\n",
    "Load images, preprocess as per Inception's requirements (-1.0 to 1.0 range).\n",
    "Resize and crop to 299 x 299 pixels.\n",
    "Use Inception v3 pre-trained model up to bottleneck layer.\n",
    "Replace output layer for new classification task.\n",
    "Split data into training and test sets for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e0bd9",
   "metadata": {},
   "source": [
    "#### 9. Large-scale image recognition using transfer learning.\n",
    "1. Make a training set of at least 100 images for each class. You might, for example, identify your own photos based on their position (beach, mountain, area, etc.) or use an existing dataset, such as the flowers dataset or MIT's places dataset (requires registration, and it is huge).\n",
    "2. Create a preprocessing phase that resizes and crops the image to 299 x 299 pixels while also adding some randomness for data augmentation.\n",
    "3. Using the previously trained Inception v3 model, freeze all layers up to the bottleneck layer (the last layer before output layer) and replace output layer with  appropriate number of outputs for your new classification task (e.g., the flowers dataset has five mutually exclusive classes so the output layer must have five neurons and use softmax activation function).\n",
    "4. Separate the data into two sets: a training and a test set. The training set is used to train the model, and the test set is used to evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5ba3f",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
