{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 12 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. Describe the Quick R-CNN architecture ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b4f9a",
   "metadata": {},
   "source": [
    "**Answer**Quick R-CNN Architecture: Quick R-CNN improves on R-CNN's speed by introducing a single-stage approach. It uses a region proposal network (RPN) to propose regions directly from the convolutional feature map, then applies RoI pooling to these regions for classification and bounding box regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. Describe two Fast R-CNN loss functions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7afd883",
   "metadata": {},
   "source": [
    "**Answer**Fast R-CNN Loss Functions:\n",
    "\n",
    "Classification Loss: Compares predicted class probabilities to ground truth labels using softmax cross-entropy.\n",
    "Bounding Box Regression Loss: Measures the difference between predicted bounding box coordinates and ground truth coordinates, often using smooth L1 loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. Describe the DISABILITIES OF FAST R-CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7efbe",
   "metadata": {},
   "source": [
    "**Answer**Disadvantages of Fast R-CNN:\n",
    "\n",
    "Separate region proposal step (RPN) is computationally expensive.\n",
    "Training can be complex due to multiple loss functions.\n",
    "Not real-time for applications needing high inference speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. Describe how the area proposal network works ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375dd038",
   "metadata": {},
   "source": [
    "**Answer**Area Proposal Network (RPN): The RPN generates anchor boxes across the entire image and predicts objectness scores and bounding box regressions for each anchor. It uses convolutional features from the image to propose regions of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. Describe how the RoI pooling layer works ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adede146",
   "metadata": {},
   "source": [
    "**Answer**RoI Pooling Layer: The RoI pooling layer resizes variable-sized RoIs from the convolutional feature map into a fixed size (e.g., 7x7) using max pooling. This ensures that features are extracted uniformly from RoIs for subsequent processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6. What are fully convolutional networks and how do they work? (FCNs) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2d539",
   "metadata": {},
   "source": [
    "**Answer**Fully Convolutional Networks (FCNs): FCNs are neural networks that use only convolutional and pooling layers for both feature extraction and spatial resolution reduction. They capture semantic information and generate pixel-wise segmentation maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. What are anchor boxes and how do you use them ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be58e4c",
   "metadata": {},
   "source": [
    "**Answer**Anchor Boxes: Anchor boxes are pre-defined bounding box shapes and sizes that are placed at various positions across the image. They serve as reference templates for object detection, helping predict object locations and sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. Describe the Single-shot Detector's architecture (SSD) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620fdbe",
   "metadata": {},
   "source": [
    "**Answer**Single-Shot Detector (SSD) Architecture: SSD is a single-stage object detection model that uses a series of convolutional layers at different scales to predict object presence, class scores, and bounding box regressions. It performs detection at multiple scales in a single forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### 9. HOW DOES THE SSD NETWORK PREDICT ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46569047",
   "metadata": {},
   "source": [
    "**Answer**SSD Network Prediction: The SSD network predicts objectness scores, class probabilities, and bounding box regressions at different scales and aspect ratios. The network uses predefined anchor boxes and matches predictions to ground truth for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff43a28",
   "metadata": {},
   "source": [
    "#### 10. Explain Multi Scale Detections ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035db9f6",
   "metadata": {},
   "source": [
    "**Answer**Multi-Scale Detections: Multi-scale detections involve detecting objects at multiple resolutions or scales in the image. This helps capture objects of varying sizes and improve detection accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29182790",
   "metadata": {},
   "source": [
    "#### 11. What are dilated (or atrous) convolutions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1780d8c",
   "metadata": {},
   "source": [
    "**Answer**Dilated (Atrous) Convolutions: Dilated convolutions involve introducing gaps between kernel elements to increase the receptive field without losing resolution. They're used in semantic segmentation tasks to capture global context information without reducing spatial dimensions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
